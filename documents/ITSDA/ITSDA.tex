% #########################################################################
% #                       EXPLORACIÓN Y ANÁLISIS DE DATOS                 #
% #########################################################################

% Definición de nombres
\newcommand{\estudiante}{García Justel, Alan}
\newcommand{\titulo}{MÁSTER EN INGENIERÍA COMPUTACIONAL Y SISTEMAS INTELIGENTES}
\newcommand{\asignatura}{INTRODUCTION TO TIME SERIES DATA}
\newcommand{\portada}{common/no_signal.png}
\newcommand{\colorportada}{title_green}
\newcommand{\curso}{2024-2025}


% Notebook
\begin{document}
\include{title} % Incluimos el título
\newpage
% Índices
\tableofcontents\thispagestyle{empty} \newpage
% \listoffigures\thispagestyle{empty}   %\newpage
% \listoftables\thispagestyle{empty}    %\newpage

\section{Introduction}
Time series data is information that represents one or more attributes (variables) over time (or another ordered dimension).
There are multiple aproximation for using a time series data for different tasks:
- Use the data directly or with a preprocessing step for noise and dimensionality reduction, split into windows of data, selecting specific parameter for represanting the time series data or other more sophisticated techniques like fourier methods.
- Use algorithms for specific data (convolutional networks for images, RNN for audio...).

\section{Time Series Forecasting}
The objective is to predict or to infer a future timestamp state for the time series.

$$
y_{t + a} = f(y_t, y_{t-1}, y_{t-2}, y_{t-3}, \dots, \text{error})
$$

Where $(y_{t}, y_{t}, y_{t})$ are the previous observations of the variables we want to predict (historical values). 
Also, it is possible to have other extra information ($(x_{1}, x_{2}, x_{3})$) that is useful for the forecasting:

$$
y_{t + a} = f(y_t, y_{t-1}, y_{t-2}, y_{t-3}, \dots, x_{1}, x_{2}, x_{3}, \dots, \text{error})
$$

\subsection{Classical lineal models}
The Classical lineal models has these assumptions:

\begin{itemize}
    \item \textbf{stochastic process}: an ordered sequence of random variables, where the
    order is typically given by time: $(Y_1, Y_2, Y_3, \dots, Y_n, \dots)$.
    \item \textbf{Time series}: a finite set of observations (a sample) from a real-valued
    stochastic process (univariate or multivariate).
\end{itemize}

We need a time series to be stationary in order to apply forecasting methods. A time series is stationary if these conditions are fulfilled:
$$
F(X_1, X_2, X_3, \dots, X_n) = P(X_1 < x_1, X_2 < x_2, X_3 < x_3, \dots, X_n < x_n)
$$
\begin{enumerate}
    \item First order stationary: $F(X_t) = F(X_{t +k})$. If the probability distribution of the first variable is the same as the second one, the same as the third one and so on.
    \item Second order stationary: $F(X_{t1}, X_{t2}) = F(X_{t1 + k}, X_{t2 + k})$.
\end{enumerate}

However, it is very difficult to have a full stationary time series, so a \textit{weak stationary} is defined:
\begin{enumerate}
    \item The mean is constant. $E(X_t)$
    \item The variance is constatnt. $\text{Var}(X_t)$
    \item The covariance si constant in terms of a parameter ($\text{Cov}(X_i, X_{i+k})=f(k)$). It depends on time difference between the random variables.
\end{enumerate}

\textbf{How do we check if a time series is stationary?}
\begin{enumerate}
    \item Visual inspection
    \item Statistical tests
\end{enumerate}

\textbf{Forecasting models for stationary time series:}
\begin{itemize}
    \item Autoregresive Models AR($p$): \textit{predict the future based on previous observations.} $X_t = f(X_{t-1}, \dots, X_{t_-p}) + \epsilon_t$
    \item Moving Average Models MA($q$): \textit{predict the future based on previous errors.} $X_t = f(\epsilon_{t-1}, \dots, \epsilon_{t_-q}) + \epsilon_t$
    \item ARMA Models: \textit{linear regression of previous observations and previous errors}.
\end{itemize}
AR, MA and ARMA processes will only fit if the original time series is stationary. There is a variation named ARIMA Models wich tries to fit an ARMA model but performing differenciation on the time series previously in order to make a non-stationary time series stationary. It has 3 parameters: $p$, from the AR part; $d$, from the differenciation part and $q$, from the MA part. There are also other extensions and variants such as ARIMAX... \textit{Auto-ARIMA} is an implementation of the ARIMA algorithm with some heuristics to search for the optimal hiperparámeters of the ARIMA model.

\textbf{Evaluation of a time series model:}

Evaluate if the residuals are white noise or not. Evaluate the prediction power of the model with metrics such as:
$$
RMSE = \sqrt{\frac{\sum_{t=1}^{N}(x_t - \hat{x}_t)^2}{N}}
$$

For cross validation see \href{https://topepo.github.io/caret/data-splitting.html}{Data splitting for Time Series}.

\end{document}