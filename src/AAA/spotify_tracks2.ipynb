{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Tracks Dataset\n",
    "__Aprendizaje Automático Avanzado (AAA)__\n",
    "\n",
    "_Alan García Justel_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paara el desarrollo de esta práctica, se ha elegido el dataset [Spotify Tracks Dataset](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset), el cual contiene información de al rededor de $125$ géneros de música distintos. Este dataset puede ser utilizado para desarrollar aplicaciones de recomentación, clasificación de canciones o ingluso de predicción de popularidad.\n",
    "\n",
    "En este notebook se va a explorar el cómo emplear las features descriptivas para realizar clasificaciones en base al género de las canciones. Estas features son tabulares y han sido recogidas de diferentes formas que se detallarán más adelante. No se va a hacer uso de las propias pistas de audio, ya que para esa labor han de intervenir técnicas de procesamiento de series temporales que se escapan del alcanze de la asignatura. Es por ello, que el objetivo recogido en el siguiente cuaderno es el de conseguir un sistema de clasificación basado en características de las canciones previamente anotadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset se proporciona en un fichero _.csv_, por lo que se ha decidido utilizar la librería de `pandas` para manejar los datos y realizar una exploración inicial de las variables presentadas. Concretamente, el dataset cuenta con $114000$ instancias y $21$ features:\n",
    "    \n",
    "* __Unamed0__: Un identificador dado a cada una de las instancias por los creadores del dataset.\n",
    "* __track_id__: El ID del track para acceder a la secuencia de audio de la canción. \n",
    "* __artists__: El o los nombres de los artistas de la canción. Si son varios están separados por _;_.\n",
    "* __album_name__: El álbum de la canción.\n",
    "* __track_name__: Nombre de la canción.\n",
    "* __popularity__: The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are. Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity.\n",
    "* __duration_ms__: Duración de la canción en ms.\n",
    "* __explicit__: Whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown)\n",
    "* __danceability__: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n",
    "* __energy__: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale\n",
    "* __key__: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1\n",
    "* __loudness__: The overall loudness of a track in decibels (dB)\n",
    "* __mode__: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0\n",
    "* __speechiness__: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks\n",
    "* __acousticness__: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic\n",
    "* __instrumentalness__: Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content\n",
    "* __liveness__: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live\n",
    "* __valence__: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
    "* __tempo__: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration\n",
    "* __time_signature__: An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of 3/4, to 7/4.\n",
    "* __track_genre__: The genre in which the track belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/AAA/spotify_tracks.csv')\n",
    "print(f\"data_frame shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al encontrarnos con estos datos nos pueden surgir varias cuestiones:\n",
    "- ¿Cuántos géneros musicales distintos presenta el dataset? \n",
    "- ¿Las clases predictoras están balanceadas?\n",
    "- ¿Hay missing values? De ser así, ¿cómo los tratamos?\n",
    "- ¿Hay entradas duplicadas? De ser así, ¿qué hacemos con ellas?\n",
    "- ¿Cómo de correlacionadas están las distintas clases predictoras?\n",
    "- ¿Qué relación existe entre las variables descriptivas como el _tempo_, por ejemplo, y los géneros musicales de las canciones?\n",
    "- ¿Realizaremos un estudio y modelos predictores para todas las clases o solo nos centraremos en un subconjunto de ellas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['track_genre'].value_counts()\n",
    "print(f\"El dataset presenta {len(counts)} géneros musicales distintos.\")\n",
    "\n",
    "distinc_nums = []\n",
    "for c in counts:\n",
    "    if c not in distinc_nums:\n",
    "        distinc_nums.append(c)\n",
    "\n",
    "if len(distinc_nums) == 1:\n",
    "    print(f\"El dataset está balanceado y cada género musical tiene {distinc_nums[0]} instancias.\")\n",
    "else:\n",
    "    print(f\"El dataset not está balanceado. Hay géneros con estos números de instancias: {distinc_nums}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una instancia del dataset que tiene todos los datos exceptuando aquellos relacionados con los nombres del artista, el álbum y el nombre de la canción. Sin embargo, sí que contamos con el _track_id_ de la canción, por lo que podemos hacer una consulta rápida mediante la _API_ de spotify para recuperar los datos faltantes de la canción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_missing_values = False\n",
    "for i, is_null in enumerate(df.isnull().sum()):\n",
    "    if is_null:\n",
    "        exist_missing_values = True\n",
    "        print(f\"La variable '{df.columns[i]}' presenta {is_null} missing values\")\n",
    "\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de ello, al hacer la consulta a la _API_ de Spotify, vemos que los datos de la canción siguen estando omitidos. Por ello, considerando que solo se trata de un único caso, de momento se va a asumir que los demás datos son correctos ya que el resto de datos parecen correctos a simple vista. Quizá más adelante resulte que esta instancia sea un outlier o ruido que deba ser tratado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_datos_cancion(track_id:str):\n",
    "    \"\"\"\n",
    "    Se ha de contar con las variables de entorno SPOTIFY_CLIENT_ID y \n",
    "    SPOTIFY_CLIENT_SECRET de Spotify Developers para poder acceder \n",
    "    a la API de Spotify.\n",
    "    \"\"\"\n",
    "    import spotipy\n",
    "    from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "    # Configura tus credenciales\n",
    "    CLIENT_ID = os.getenv(\"SPOTIFY_CLIENT_ID\")\n",
    "    CLIENT_SECRET = os.getenv(\"SPOTIFY_CLIENT_SECRET\")\n",
    "    if not CLIENT_ID or not CLIENT_SECRET:\n",
    "        raise ValueError(\"Asegúrate de que las variables de entorno SPOTIFY_CLIENT_ID y SPOTIFY_CLIENT_SECRET están configuradas.\")\n",
    "\n",
    "    # Autenticación\n",
    "    auth_manager = SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n",
    "    sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "    # Imprimir el nombre de la canción y el artista\n",
    "    track_info = sp.track(track_id)\n",
    "    print(f\"Nombre de la canción: {track_info['name']}\")\n",
    "    print(f\"Artista: {'; '.join(artist['name'] for artist in track_info['artists'])}\")\n",
    "\n",
    "buscar_datos_cancion(track_id=\"1kR4gIb7nGxHPI3D2ifs59\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, no existen instancias duplicadas :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Existen {duplicates} instancias duplicadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo esto, vamos a centrarnos en aquellas variables relevantes para desarrollar la aplicación de clasificación de canciones. Por ello, las variables `\"Unnamed: 0\"`, `\"track_id\"`, `\"artists\"`, `\"album_name\"` y `\"track_name\"` no se van a tener en cuenta. Además, también se va a codificar la variable predictora asignando un identificador numérico a cada género musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar la variable 'track_genre' para análisis\n",
    "LE = LabelEncoder()\n",
    "df[\"track_genre_encoded\"] = LE.fit_transform(df[\"track_genre\"])\n",
    "\n",
    "columns_to_drop = [\"Unnamed: 0\", \"track_id\", \"artists\", \"album_name\", \"track_name\", \"track_genre\"]\n",
    "for c in columns_to_drop:\n",
    "    if c in df.columns:\n",
    "        df = df.drop(columns=c)\n",
    "\n",
    "# Convertir todas las variables a float por consistencia de tipos\n",
    "for col in df.select_dtypes(include=[\"int64\"]).columns:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Mapa de calor de correlaciones (incluyendo género codificado)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Valores de las correlaciones entre las variables y el género musical\")\n",
    "print(correlation_matrix[\"track_genre_encoded\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que salta a la vista al observar esta matriz de correlaciones es que no está muy clara la relación entre las variables y el género musical. La intuición inicial planteaba la siguiente hypótesis inductiva: \"Las canciones de rock suelen tener mucha energía y suelen tener un volumen alto, mientras que las pistas de música clásica son más relajadas, por lo que existe una correlación fuerte entre las variables tabulares y los géneros musicales\". Sin embargo, podemos sacar algunas conclusiones preliminares a partir de esta matriz de correlaciones:\n",
    "- La durabilidad de las canciones está devilmente correlacionada con "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizar los datos\n",
    "non_feature_columns = [\"track_genre_encoded\"]\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop(columns=non_feature_columns))\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df.drop(columns=non_feature_columns).columns)\n",
    "df_scaled['track_genre_encoded'] = df['track_genre_encoded'].values\n",
    "df = df_scaled\n",
    "\n",
    "# Agrupar por género\n",
    "genre_profiles = df.groupby('track_genre_encoded').mean()\n",
    "\n",
    "# Calcular una matriz de distancia entre géneros\n",
    "# metric: ['euclidean', 'cosine', 'correlation']\n",
    "distance_matrix = pdist(genre_profiles, metric='euclidean')\n",
    "distance_df = pd.DataFrame(\n",
    "    squareform(distance_matrix),\n",
    "    index=genre_profiles.index,\n",
    "    columns=genre_profiles.index\n",
    ")\n",
    "\n",
    "# Visualizar la matriz de distancias\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(distance_df, cmap='coolwarm', xticklabels=True, yticklabels=True)\n",
    "plt.title('Similitud entre géneros basada en características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista de pares de géneros con sus distancias\n",
    "processed_pairs = set()\n",
    "pairs = []\n",
    "for genre1 in distance_df.columns:\n",
    "    for genre2 in distance_df.columns:\n",
    "        if genre1 != genre2:\n",
    "            # Esto se puede hacer porque estamos considerando una funcion de distancia es simétrica            \n",
    "            if (genre1, genre2) not in processed_pairs and (genre2, genre1) not in processed_pairs:\n",
    "                pairs.append((int(genre1), int(genre2), distance_df.loc[genre1, genre2]))\n",
    "                processed_pairs.add((genre1, genre2))\n",
    "                \n",
    "\n",
    "# Convertir la lista en un DataFrame\n",
    "pairs_df = pd.DataFrame(pairs, columns=['genre_encoded_1', 'genre_encoded_2', 'distance'])\n",
    "pairs_df['genre_1'] = LE.inverse_transform( pairs_df['genre_encoded_1'] )\n",
    "pairs_df['genre_2'] = LE.inverse_transform( pairs_df['genre_encoded_2'] )\n",
    "sorted_pairs = pairs_df.sort_values(by='distance')\n",
    "\n",
    "print(\"Lista de pares de géneros musicales más similares en base a la disimilaridad calculada:\")\n",
    "pd.set_option('display.max_rows', None)  # Muestra todas las filas\n",
    "pd.set_option('display.max_columns', None)  # Muestra todas las columnas\n",
    "pd.set_option('display.width', None)  # Evita el corte de texto largo\n",
    "print(sorted_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos calculando la matriz de similitudes en base a las distancias de las medias normalizadas de cada una de las variables agrupadas por género. Es por ello que surge la siguiente cuestión: ¿Son la media y la desviación típica estadísticos representativos de las variables?\n",
    "\n",
    "Para que fuese así, los datos deberían de estar simétricamente distribuidos, no deberían de estar sesgados (poca presencia de outliers) y no deberían de ser asimétricos. Por ello, se ha decidido representar las distribuciones de cada una de las variables en un violin plot en el cual se puede distinguir visualmente. Así, se puede observar cómo muy pocas variables se aproximan a una distribución normal a excepción  de las variables de duración y \"bailabilidad\", las cuales sí se asemejan en cierta manera a una distribución normal (al menos de forma visual). Además, \n",
    "\n",
    "\n",
    "La variable `mode` es booleana, no es representativo el violin plot. \n",
    "La variable `time_signature` toma valores discretos 0-7, no es representativo el violin plot.\n",
    "La variable `liveness` o de presencia de multitudes en el audio parece presentar outliers.\n",
    "La variable `speechiness` también parece presentar outliers a la derecha.\n",
    "\n",
    "\n",
    "En este punto nos encontramos con dos vías de estudio principales. En primer lugar, hay que comprobar si efectivamente las variables de duración y \"bailabilidad\" siguen distribuciones normales o es solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis, shapiro\n",
    "\n",
    "selected_columns = ['acousticness', 'valence', 'liveness', 'popularity', 'danceability', 'key', \n",
    "                    'tempo', 'loudness', 'duration_ms', 'energy', 'instrumentalness', 'speechiness' ]\n",
    "# Non selected columns: track_genre_encoded, mode, explicit, time_signature\n",
    "print(len(selected_columns))\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "# Violin plot para cada variable numérica\n",
    "stat_data = {}\n",
    "for i, column in enumerate(selected_columns):\n",
    "    sns.violinplot(x=df[column], color='lightblue', ax=axes[i])\n",
    "    axes[i].set_title(f'Distribución de {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "\n",
    "    # Cálculo de asimetría y curtosis\n",
    "    mean = df[column].mean()\n",
    "    std_dev = df[column].std()\n",
    "    column_skewness = skew(df[column].dropna())\n",
    "    column_kurtosis = kurtosis(df[column].dropna())\n",
    "    stat, p_value = shapiro(df[column].dropna())\n",
    "    \n",
    "    stat_data[column] = {\n",
    "        \"mean\": mean,\n",
    "        \"std_dev\": std_dev,\n",
    "        \"skewness\": column_skewness,\n",
    "        \"kurtosis\": column_kurtosis,\n",
    "        \"shapiro\":{\"stat\": stat, \"p_value\": p_value}\n",
    "    }\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sd in stat_data.keys():\n",
    "    if stat_data[sd]['shapiro']['p_value'] > 1e-10:\n",
    "        print(stat_data[sd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data['duration_ms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ninguna variable parece presentar un p-valor superior a $1 \\times 10^{-10}$ en el test de _Saphiro-Wilk_, por lo que es estadisticamente significativo el decir que ninguna de ellas se aproxima a una distribución normal. Por otro lado, es interesante realizar este mismo estudio visual agrupando los datos por su género musical correspondiente ya que puede darse el caso de que las anomalías y distintas distribuciones se deban al agrupamiento y el estudio global de todos los datos sin tener en cuenta los géneros musicales de cada instancia.\n",
    "Sin embargo, al haber 114 géneros musicales distintos, es complicada la visualización en este tipo de diagrama. \n",
    "\n",
    "\n",
    "Por ello, se proponen dos métodos para realizar la visualización:\n",
    "1. Agrupar los géneros musicales empleando un algoritmo de clustering aglomerativo generando clusters en base a la matriz de similaridad expuesta anteriormente.\n",
    "2. Seleccionar de forma aleatoria un género musical y visualizar su distribución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 15 # partiendo de 114\n",
    "clustering = AgglomerativeClustering(n_clusters=n_clusters, metric='precomputed', linkage='complete')\n",
    "cluster_labels = clustering.fit_predict(squareform(distance_matrix))\n",
    "\n",
    "# Crear un DataFrame para ver cómo se agrupan los géneros\n",
    "clustered_genres = pd.DataFrame({\n",
    "    'track_genre_encoded': distance_df.columns,\n",
    "    'cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Asignar los nuevos clusters a los géneros musicales\n",
    "clustered_genres['track_genre'] = LE.inverse_transform(clustered_genres['track_genre_encoded'].astype(int))\n",
    "print(\"Agrupaciones de géneros musicales calculadas:\")\n",
    "CE = clustered_genres.groupby('cluster')['track_genre'].apply(list) # Cluster Encoder\n",
    "print(CE)\n",
    "\n",
    "metal_assert = ['black-metal', 'death-metal', 'grindcore', 'heavy-metal', 'industrial', 'metalcore']\n",
    "assert CE[0] == metal_assert\n",
    "\n",
    "# Hacer un violin plot por cada variable y cada cluster agrupando los datos\n",
    "df['cluster'] = df['track_genre_encoded'].map(clustered_genres.set_index('track_genre_encoded')['cluster'])\n",
    "selected_columns = ['acousticness', 'valence', 'liveness', 'popularity', 'danceability', 'key', \n",
    "                    'tempo', 'loudness', 'duration_ms', 'energy', 'instrumentalness', 'speechiness']\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "for i, column in enumerate(selected_columns):\n",
    "    sns.violinplot(x='cluster', y=column, data=df, color='purple', inner=\"quart\", ax=axes[i])\n",
    "    axes[i].set_title(f'Distribución de {column} por cluster')\n",
    "    axes[i].set_xlabel(column)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['acousticness', 'valence', 'liveness', 'popularity', 'danceability', 'key', \n",
    "                    'tempo', 'loudness', 'duration_ms', 'energy', 'instrumentalness', 'speechiness' ]\n",
    "# Non selected columns: track_genre_encoded, mode, explicit, time_signature\n",
    "print(len(selected_columns))\n",
    "selected_genre = np.random.randint(low=0, high=len(LE.classes_))\n",
    "filtered_df = df[df['track_genre_encoded'] == selected_genre]\n",
    "\n",
    "# Crear un gráfico de violín para cada columna seleccionada\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "for i, column in enumerate(selected_columns):\n",
    "    plt.figure(figsize=(10, 6))  # Tamaño de cada gráfico\n",
    "    sns.violinplot(y=column, data=filtered_df, inner=\"quart\", color=\"lightgreen\", ax=axes[i])\n",
    "    axes[i].set_title(f'Distribución de {column} para el la clase {LE.classes_[selected_genre]}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La conclusión general es que ni agrupando por clusters o por clases se consiguen datos distribuidos de forma normal. Esto puede deberse a que las canciones, aunque pertenezcan a un género en específico, pueden contener rasgos de otros géneros musicales. No todo es blanco o negro. Es por ello que también es interesante detectar estos outliers para ver cómo se comportan. Además, a la hora de hacer un clasificador quizás no sea lo óptimo uno que clasifique canciones proporcionando un único género musical como salida, si no un abanico de distintos géneros musicales con mayor o menor probabilidades.\n",
    "\n",
    "Considerando este análisis, los clústeres de agrupación obtenido y los objetivos didácticos de esta práctica, se propone estudiar un problema de clasificación binaria en el que se pretende detectar si una instancia pertenece al siguiente grupo de canciones o no:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_genres.groupby('cluster')['track_genre'].apply(list)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the binary target variable\n",
    "df['is_metal'] = df['cluster'].apply(lambda x: 1 if x == 0 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metal_data = df[df['is_metal'] == 1]\n",
    "\n",
    "non_feature_columns = [\"track_genre_encoded\", \"cluster\", \"is_metal\"]\n",
    "metal_numeric = metal_data.drop(columns=non_feature_columns)\n",
    "correlation_matrix = metal_numeric.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriz de correlación de las variables para el clúster \"Metal\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este clúster se recogen los géneros de la conocida como música _metal_ y que está caracterizada por su alta _energía_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature_columns = [\"track_genre_encoded\", \"cluster\", \"is_metal\"]\n",
    "X = df.drop(columns=non_feature_columns)  # Features\n",
    "y = df['is_metal']  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(X)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "print(\"PCA Varianza Acumulada:\\n\", cumulative_explained_variance)\n",
    "\n",
    "# Dataframe con los datos del PCA para los plots\n",
    "pca_df = pd.DataFrame(data=pca_result[:, :3], columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df['cluster'] = df['cluster'].values\n",
    "\n",
    "# Mostrar el scree plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.xlabel('Número de componentes principales')\n",
    "plt.ylabel('Autovalor')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()\n",
    "\n",
    "# 2D Features con PCA\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['cluster'], cmap='tab20', alpha=0.6)\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(f\"2D PCA Plot con varianza acumulada de {cumulative_explained_variance[1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El grafico no es nada representativo. Varianza acumulada muy baja y tampoco mejora con las 3 primeras componentes principales. Este método de visualización no es adecuado en este caso y no nos aporta nueva información. Ya sabíamos que las clases parecen estar muy aglomeradas y los géneros musicales normalmente combinan elementos unos de otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, learning_rate=200, max_iter=1000)\n",
    "tsne_result = tsne.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame with t-SNE results\n",
    "tsne_df = pd.DataFrame(data=tsne_result, columns=['TSNE1', 'TSNE2'])\n",
    "tsne_df['track_genre_encoded'] = df['track_genre_encoded'].values\n",
    "tsne_df['cluster'] = df['cluster'].values\n",
    "\n",
    "# t_SNE Clusters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "scatter1 = axes[0].scatter(tsne_df['TSNE1'], tsne_df['TSNE2'], c=tsne_df['cluster'], cmap='tab20', alpha=0.6)\n",
    "axes[0].set_title(\"t-SNE por cada clúster\")\n",
    "axes[0].set_xlabel(\"t-SNE Dimensión 1\")\n",
    "axes[0].set_ylabel(\"t-SNE Dimensión 2\")\n",
    "fig.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# t_SNE Genres\n",
    "scatter2 = axes[1].scatter(tsne_df['TSNE1'], tsne_df['TSNE2'], c=tsne_df['track_genre_encoded'], cmap='tab20', alpha=0.6)\n",
    "axes[1].set_title(\"t-SNE por cada género etiquetado\")\n",
    "axes[1].set_xlabel(\"t-SNE Dimensión 1\")\n",
    "axes[1].set_ylabel(\"t-SNE Dimensión 2\")\n",
    "fig.colorbar(scatter2, ax=axes[1], label='Genre')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha comentado, la asignación de un género musical a una canción no siempre es clara. Además, en este caso de estudio, estamos considerando el género musical \"metal\" para realizar el estudio, género que a su vez es una agrupación de otros subgéneros y ya se ha visto como las variables descriptivas de las canciones no siguen una distribución normal, son asimétricas y parecen presentar outliers.\n",
    "Por esta razón es muy interesante determinar con qué tipo de outliers nos podemos encontrar y determinar si a la hora de entrenar un clasificador es mejor considerar o no considerar estas canciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una primera opción que, aunque sencilla, se ve interesante es el de asumir que las features deben de seguir una distribución normal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que df es tu DataFrame con las características normalizadas o no normalizadas\n",
    "\n",
    "# Paso 1: Calcular Z-Score para todas las features\n",
    "z_scores = np.abs(zscore(X))\n",
    "\n",
    "# Paso 2: Identificar outliers\n",
    "threshold = 3  # Umbral para considerar un outlier\n",
    "outliers = (z_scores > threshold).any(axis=1)\n",
    "\n",
    "# Agregar columna indicando si el punto es un outlier\n",
    "\n",
    "# Paso 3: Resumen de outliers detectados\n",
    "print(f\"Total de outliers detectados: {df['is_outlier'].sum()}\")\n",
    "\n",
    "# Paso 4: Visualización de outliers (usando PCA para reducir a 2D si es necesario)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reducir a 2D para visualizar\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# Crear DataFrame con PCA y etiquetas de outliers\n",
    "pca_df = pd.DataFrame(pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['is_outlier'] = outliers\n",
    "\n",
    "# Graficar puntos normales y outliers\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_df[~pca_df['is_outlier']]['PC1'], pca_df[~pca_df['is_outlier']]['PC2'], alpha=0.6, label='Normal', c='blue')\n",
    "plt.scatter(pca_df[pca_df['is_outlier']]['PC1'], pca_df[pca_df['is_outlier']]['PC2'], alpha=0.6, label='Outlier', c='red')\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Detección de Outliers usando Z-Score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detección de outliers basado en vecindad. Concretamente se va a calcular el Local Outlier Factor o LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LocalOutlierFactor #####################################################################\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "outliers_pred = clf.fit_predict(df.drop(columns=non_feature_columns))\n",
    "outlierness = pd.DataFrame({\"outlierness\": clf.negative_outlier_factor_, \"outliers_pred\": outliers_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar el outlierness de cada instancia con un scatter\n",
    "def plot_raius_outlierness(X: pd.DataFrame, Y:pd.DataFrame, outlierness: pd.DataFrame):\n",
    "    # Los labels reales se utiilzan únicamente para visualizar\n",
    "    # En un entorno real no se contaría con Y\n",
    "\n",
    "    label2color = {\n",
    "        0: (0, 0, 0),\n",
    "        1: (162, 78, 255)\n",
    "    }\n",
    "\n",
    "    # Para calcular el scree graph\n",
    "    all_pca = PCA(n_components=len(X.columns))\n",
    "    all_pca.fit(X)\n",
    "    # print(f\"PLOTTING OUTLIERNESS\\nPCA variabilidad: {all_pca.explained_variance_ratio_}\\nAutovalores: {all_pca.singular_values_}\")\n",
    "    \n",
    "    # Reducir a las 2 dimensiones más representativas con PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    radius = (outlierness[\"outlierness\"].max() - outlierness[\"outlierness\"]) / (outlierness[\"outlierness\"].max() - outlierness[\"outlierness\"].min())\n",
    "    color = Y.map(lambda label: label2color[label])\n",
    "\n",
    "    # Plotear el scree graph y las instancias-outlierness\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    ax1.set_title('Local Outlier Factor (LOF)')\n",
    "    ax1.scatter(X_reduced[:, 0], X_reduced[:, 1], color=color, s=7.0, label=\"Data points\")\n",
    "    ax1.scatter(X_reduced[:, 0], X_reduced[:, 1], s=1000 * radius, edgecolors=\"r\", facecolors=\"none\", label=\"Outlier scores\")\n",
    "    ax1.set(xlabel='PCA1', ylabel='PCA2')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.set_title('PCA Scree Graph')\n",
    "    ax2.plot(range(1,len(all_pca.singular_values_ )+1), all_pca.singular_values_, marker='o', c='blue', label='Variabilidad PCA')\n",
    "    ax2.set(xlabel='component number', ylabel='Eigen value')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#plot_raius_outlierness(df.drop(columns=non_feature_columns), df.drop(columns='is_metal'), outlierness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
